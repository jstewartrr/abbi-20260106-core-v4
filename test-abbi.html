<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ABBI Test - GPT-4o with MCP Tools</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
        }
        .panel {
            background: white;
            border-radius: 24px;
            padding: 30px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
        }
        h1 {
            text-align: center;
            color: #667eea;
            margin-bottom: 10px;
            grid-column: 1 / -1;
        }
        .subtitle {
            text-align: center;
            color: white;
            margin-bottom: 20px;
            font-size: 14px;
            grid-column: 1 / -1;
        }
        .avatar-wrapper {
            width: 400px;
            height: 400px;
            margin: 0 auto 20px;
            cursor: pointer;
            transition: transform 0.3s ease;
            position: relative;
            overflow: hidden;
        }
        .avatar-wrapper:hover {
            transform: scale(1.02);
        }
        .avatar-wrapper.listening {
            box-shadow: 0 0 0 4px rgba(102, 126, 234, 0.3);
        }
        .avatar-wrapper.speaking {
            box-shadow: 0 0 0 4px rgba(156, 39, 176, 0.5);
        }
        .avatar {
            width: 100%;
            height: 100%;
            border-radius: 24px;
            object-fit: cover;
            box-shadow: 0 10px 30px rgba(102, 126, 234, 0.4);
            background: #f0f0f0;
        }
        .status-text {
            text-align: center;
            font-size: 18px;
            color: #333;
            margin-bottom: 20px;
            min-height: 28px;
        }
        .btn {
            width: 100%;
            padding: 16px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border: none;
            border-radius: 12px;
            font-size: 16px;
            font-weight: 600;
            cursor: pointer;
            transition: transform 0.2s ease, box-shadow 0.2s ease;
            margin-bottom: 10px;
        }
        .btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 20px rgba(102, 126, 234, 0.4);
        }
        .btn:active {
            transform: translateY(0);
        }
        .btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }
        .transcription-box {
            background: #f8f9fa;
            border-radius: 12px;
            padding: 20px;
            height: 400px;
            overflow-y: auto;
            margin-bottom: 20px;
        }
        .transcription-box h3 {
            color: #333;
            margin-bottom: 15px;
            font-size: 16px;
        }
        .transcript-message {
            margin-bottom: 15px;
            padding: 12px;
            border-radius: 8px;
        }
        .transcript-message.user {
            background: #e3f2fd;
            border-left: 4px solid #2196f3;
        }
        .transcript-message.assistant {
            background: #f3e5f5;
            border-left: 4px solid #9c27b0;
        }
        .transcript-message.tool {
            background: #fff3e0;
            border-left: 4px solid #ff9800;
            font-size: 13px;
        }
        .transcript-label {
            font-weight: 600;
            font-size: 12px;
            text-transform: uppercase;
            margin-bottom: 5px;
            color: #666;
        }
        .transcript-text {
            color: #333;
            line-height: 1.5;
        }
        .text-input-box {
            background: #f8f9fa;
            border-radius: 12px;
            padding: 20px;
        }
        .text-input-box h3 {
            color: #333;
            margin-bottom: 15px;
            font-size: 16px;
        }
        .text-input-form {
            display: flex;
            gap: 10px;
        }
        .text-input {
            flex: 1;
            padding: 12px;
            border: 2px solid #ddd;
            border-radius: 8px;
            font-size: 14px;
        }
        .text-input:focus {
            outline: none;
            border-color: #667eea;
        }
        .send-btn {
            padding: 12px 24px;
            background: #667eea;
            color: white;
            border: none;
            border-radius: 8px;
            font-weight: 600;
            cursor: pointer;
        }
        .send-btn:hover {
            background: #5568d3;
        }
        .send-btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }
        .info-box {
            background: #e3f2fd;
            border-left: 4px solid #2196f3;
            padding: 15px;
            margin-top: 20px;
            border-radius: 8px;
            font-size: 13px;
            color: #1565c0;
        }
        .info-box strong {
            display: block;
            margin-bottom: 8px;
        }
        .info-box ul {
            margin-left: 20px;
            margin-top: 8px;
        }
        @media (max-width: 768px) {
            .container {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <h1>üß™ ABBI Test Environment</h1>
    <div class="subtitle">abbi-openai ‚Ä¢ GPT-4o + MCP Tools</div>
    
    <div class="container">
        <!-- Left Panel: Voice Control -->
        <div class="panel">
            <div class="avatar-wrapper" id="abbiAvatar" onclick="toggleABBI()">
                <video id="abbiVideo"
                       class="avatar"
                       autoplay
                       playsinline
                       muted
                       poster="https://lh3.googleusercontent.com/d/1mEGmRYYQ_3exRbYYF7CyznYvcrHzPrPs=w400">
                </video>
            </div>

            <div class="status-text" id="abbiStatus">Tap to start voice session</div>

            <button class="btn" id="toggleBtn" onclick="toggleABBI()">Start Voice Session</button>

            <div class="info-box">
                <strong>Testing Checklist:</strong>
                <ul>
                    <li>Ask: "What are the recent Hive Mind entries?"</li>
                    <li>Ask: "Search for website in Hive Mind"</li>
                    <li>Say: "Remember that I prefer GPT-4o"</li>
                    <li>Test "wait" command - she should stay quiet</li>
                </ul>
            </div>
        </div>

        <!-- Right Panel: Transcription & Text Input -->
        <div class="panel">
            <div class="transcription-box" id="transcriptionBox">
                <h3>üìù Live Transcription</h3>
                <div id="transcripts"></div>
            </div>

            <div class="text-input-box">
                <h3>‚å®Ô∏è Type Your Question</h3>
                <div class="text-input-form">
                    <input type="text" 
                           id="textInput" 
                           class="text-input" 
                           placeholder="Type a question for ABBI to answer verbally..."
                           disabled>
                    <button class="send-btn" id="sendBtn" onclick="sendTextMessage()" disabled>Send</button>
                </div>
                <div style="font-size: 12px; color: #666; margin-top: 10px;">
                    Start voice session first, then type messages for ABBI to respond verbally
                </div>
            </div>
        </div>
    </div>

    <script type="module">
        const AGENT_ID = 'agent_2501ketq01k7e4vrnbrvvefa99ej';
        let abbiConversation = null;

        function addTranscript(type, text, label = '') {
            const transcripts = document.getElementById('transcripts');
            const message = document.createElement('div');
            message.className = `transcript-message ${type}`;
            
            const labelDiv = document.createElement('div');
            labelDiv.className = 'transcript-label';
            labelDiv.textContent = label || (type === 'user' ? 'You' : type === 'assistant' ? 'ABBI' : 'System');
            
            const textDiv = document.createElement('div');
            textDiv.className = 'transcript-text';
            textDiv.textContent = text;
            
            message.appendChild(labelDiv);
            message.appendChild(textDiv);
            transcripts.appendChild(message);
            
            // Auto-scroll to bottom
            const box = document.getElementById('transcriptionBox');
            box.scrollTop = box.scrollHeight;
        }

        async function getSignedUrl() {
            const response = await fetch(`/api/get-signed-url?agent_id=${AGENT_ID}`);
            if (!response.ok) {
                const err = await response.json();
                throw new Error(err.error || 'Failed to get signed URL');
            }
            const data = await response.json();
            return data.signed_url;
        }

        window.sendTextMessage = function() {
            const input = document.getElementById('textInput');
            const message = input.value.trim();
            
            if (!message || !abbiConversation) return;
            
            // Add to transcript
            addTranscript('user', message);
            
            // Send to ABBI
            try {
                abbiConversation.sendTextMessage(message);
                input.value = '';
            } catch (error) {
                console.error('Error sending text message:', error);
            }
        };

        // Handle Enter key in text input
        document.addEventListener('DOMContentLoaded', () => {
            const input = document.getElementById('textInput');
            input.addEventListener('keypress', (e) => {
                if (e.key === 'Enter') {
                    sendTextMessage();
                }
            });
        });

        window.toggleABBI = async function() {
            const avatar = document.getElementById('abbiAvatar');
            const status = document.getElementById('abbiStatus');
            const toggleBtn = document.getElementById('toggleBtn');
            const textInput = document.getElementById('textInput');
            const sendBtn = document.getElementById('sendBtn');

            // If already in conversation, end it
            if (abbiConversation) {
                try {
                    await abbiConversation.endSession();
                } catch (e) {
                    console.error('Error ending session:', e);
                }

                // Clear video stream
                const videoElement = document.getElementById('abbiVideo');
                if (videoElement && videoElement.srcObject) {
                    videoElement.srcObject.getTracks().forEach(track => track.stop());
                    videoElement.srcObject = null;
                }

                abbiConversation = null;
                avatar.classList.remove('listening', 'speaking');
                status.textContent = 'Tap to start voice session';
                toggleBtn.textContent = 'Start Voice Session';
                textInput.disabled = true;
                sendBtn.disabled = true;
                return;
            }

            try {
                status.textContent = 'Connecting to ABBI...';
                avatar.classList.add('listening');
                toggleBtn.disabled = true;

                // Request microphone permission
                await navigator.mediaDevices.getUserMedia({ audio: true });

                // Get signed URL
                status.textContent = 'Getting secure connection...';
                const signedUrl = await getSignedUrl();

                // Import ElevenLabs client
                const { Conversation } = await import('https://esm.sh/@elevenlabs/client@0.12.2');

                // Start conversation with video enabled
                status.textContent = 'Starting voice session...';
                abbiConversation = await Conversation.startSession({
                    signedUrl: signedUrl,
                    clientTools: {
                        video: true
                    },
                    onConnect: () => {
                        console.log('Connected');
                        status.textContent = '‚úÖ Connected - Speak or type';
                        avatar.classList.remove('listening');
                        avatar.classList.add('speaking');
                        toggleBtn.textContent = 'End Session';
                        toggleBtn.disabled = false;
                        textInput.disabled = false;
                        sendBtn.disabled = false;
                    },
                    onVideoStream: (stream) => {
                        console.log('üìπ Video stream received');
                        const videoElement = document.getElementById('abbiVideo');
                        if (videoElement && stream) {
                            videoElement.srcObject = stream;
                            videoElement.play().catch(e => console.error('Video play error:', e));
                        }
                    },
                    onDisconnect: () => {
                        console.log('Disconnected');
                        status.textContent = 'Session ended';
                        avatar.classList.remove('listening', 'speaking');

                        // Clear video stream
                        const videoElement = document.getElementById('abbiVideo');
                        if (videoElement && videoElement.srcObject) {
                            videoElement.srcObject.getTracks().forEach(track => track.stop());
                            videoElement.srcObject = null;
                        }

                        abbiConversation = null;
                        toggleBtn.textContent = 'Start Voice Session';
                        toggleBtn.disabled = false;
                        textInput.disabled = true;
                        sendBtn.disabled = true;
                    },
                    onMessage: (message) => {
                        console.log('üì® Message received:', message);
                        
                        // Extract text from various message formats
                        const text = message.message || message.content || message.text || '';
                        
                        // User messages
                        if (message.type === 'user_transcript' || message.role === 'user') {
                            if (text) addTranscript('user', text);
                        } 
                        // Agent/Assistant responses - try multiple formats
                        else if (message.type === 'agent_response' || 
                                 message.type === 'agent_response_correction' ||
                                 message.role === 'assistant' ||
                                 message.source === 'ai') {
                            if (text) addTranscript('assistant', text);
                        }
                        // Tool calls
                        else if (message.type === 'tool_call') {
                            const toolName = message.tool_name || message.name || 'Tool';
                            addTranscript('tool', `üîß ${toolName}`, 'Tool');
                        }
                        // Catch any text-containing messages we might have missed
                        else if (text && text.length > 0) {
                            // Log unknown message type for debugging
                            console.log('üîç Unknown message type:', message.type, '- Text:', text);
                            // If it seems like assistant content, show it
                            if (message.type && message.type.includes('agent')) {
                                addTranscript('assistant', text);
                            }
                        }
                    },
                    onError: (error) => {
                        console.error('ABBI error:', error);
                        status.textContent = '‚ùå Error - Check console';
                        avatar.classList.remove('listening', 'speaking');

                        // Clear video stream
                        const videoElement = document.getElementById('abbiVideo');
                        if (videoElement && videoElement.srcObject) {
                            videoElement.srcObject.getTracks().forEach(track => track.stop());
                            videoElement.srcObject = null;
                        }

                        abbiConversation = null;
                        toggleBtn.textContent = 'Start Voice Session';
                        toggleBtn.disabled = false;
                        textInput.disabled = true;
                        sendBtn.disabled = true;
                    },
                    onModeChange: (mode) => {
                        if (mode.mode === 'listening') {
                            avatar.classList.remove('speaking');
                            avatar.classList.add('listening');
                            status.textContent = 'üëÇ Listening...';
                        } else if (mode.mode === 'speaking') {
                            avatar.classList.remove('listening');
                            avatar.classList.add('speaking');
                            status.textContent = 'üó£Ô∏è ABBI speaking...';
                        }
                    }
                });

            } catch (error) {
                console.error('ABBI connection error:', error);
                avatar.classList.remove('listening', 'speaking');

                // Clear video stream in case of error
                const videoElement = document.getElementById('abbiVideo');
                if (videoElement && videoElement.srcObject) {
                    videoElement.srcObject.getTracks().forEach(track => track.stop());
                    videoElement.srcObject = null;
                }

                toggleBtn.disabled = false;
                toggleBtn.textContent = 'Start Voice Session';

                if (error.name === 'NotAllowedError') {
                    status.textContent = '‚ùå Microphone access denied';
                } else {
                    status.textContent = '‚ùå Connection failed';
                }
                abbiConversation = null;
            }
        }
    </script>
</body>
</html>
